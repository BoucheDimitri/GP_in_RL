# Bayesian Policy Gradient  

Running Main_BPG.py generates 3 different different experiments in which we compare the efficiency of the BPG algorithms as well as the Monte Carlo's method. For this, we try to minimize the cumulative regret by optimizing a parameter denote $ \theta$. The optimization of this parameter is done through a gradient descent using an empirical estimate of the gradient.
